---
title: Publication
permalink: /publication/
---

We try to include links for all of our recent papers. Most links direct you to a journal's site where that particular publication is available for download. If you cannot access one of our papers, let us know.  For a more complete list, see Michael's [google scholar citations profile](https://scholar.google.com/citations?user=DZ9-LmkAAAAJ&hl=en).

<hr>

### 2024

_Beyond Linear Response: Equivalence between Thermodynamic Geometry and Optimal Transport_<br>
Adrianne Zhong and Michael DeWeese <br>
[[arXiv]](https://arxiv.org/abs/2404.01286)

_More is Better in Modern Machine Learning: when Infinite Overparameterization is Optimal and Overfitting is Obligatory_<br>
James Simon, Dhruva Karkada, Nikhil Ghosh, Mikhail Belkin <br>
[[ICLR '24]](https://openreview.net/pdf?id=OdpIjS0vkO) [[arXiv]](https://arxiv.org/abs/2311.14646)

_The lazy (NTK) and rich (Î¼P) regimes: a gentle tutorial_<br>
Dhruva Karkada <br>
[[arXiv]](https://arxiv.org/abs/2404.19719)

### 2023

_The eigenlearning framework: A conservation law perspective on kernel ridge regression and wide neural networks_<br>
James Simon, Madeline Dickens, Dhruva Karkada, Michael DeWeese<br>
[[TMLR '23]](https://openreview.net/pdf?id=FDbQGCAViI) [[arXiv]](https://arxiv.org/abs/2110.03922) [[code]](https://github.com/james-simon/eigenlearning)

_Shortcut engineering of active matter: run-and-tumble particles_<br>
Adam Frim and Michael DeWeese <br>
[[arXiv]](https://arxiv.org/abs/2304.06023)

_Time-Asymmetric Fluctuation Theorem and Efficient Free Energy Estimation_<br>
Adrianne Zhong, Benjamin Kuznets-Speck, Michael DeWeese <br>
[[arXiv]](https://arxiv.org/abs/2304.12287v3)

_A Spectral Condition for Feature Learning_<br>
Greg Yang, James Simon, Jeremy Bernstein <br>
[[arXiv]](https://arxiv.org/abs/2310.17813)

_On the Stepwise Nature of Self-Supervised Learning_<br>
James Simon, Maksis Knutins, Liu Ziyin, Daniel Geisz, Abraham Fetterman, Joshua Albrecht <br>
[[arXiv]](https://arxiv.org/abs/2303.15438)

### 2022

_Reverse Engineering the Neural Tangent Kernel_<br>
James Simon, Sajant Anand, Michael DeWeese<br>
[[ICML '22]](https://proceedings.mlr.press/v162/simon22a/simon22a.pdf) [[arXiv]](https://arxiv.org/abs/2106.03186v1) [[code]](https://github.com/james-simon/shallow-learning)

_Geometric Bound on the Efficiency of Irreversible Thermodynamic Cycles_<br>
Adam Frim and Michael DeWeese<br>
[[PRL '22]](https://redwood.berkeley.edu/wp-content/uploads/2022/07/FrimGeometric2022.pdf)

_Optimal Finite-Time Brownian Carnot Engine_<br>
Adam Frim and Michael DeWeese<br>
[[PRE '22]](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.105.L052103)

_Limited-control optimal protocols arbitrarily far from equilibrium_<br>
Adrianne Zhong and Michael DeWeese<br>
[[arXiv]](https://arxiv.org/pdf/2205.08662.pdf)

_A Solution to the Fokker-Planck Equation for Slowly Driven Brownian Motion: Emergent Geometry and a Formula for the Corresponding Thermodynamic Metric_<br>
Neha Wadia, Ryan Zarcone, Michael DeWeese<br>
[[PRE]](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.105.034130)

_Sparse coding models predict a spectral bias in the development of primary visual cortex (V1) receptive fields_<br>
Andrew Ligeralde and Michael DeWeese<br>
[[bioRxiv]](https://www.biorxiv.org/content/10.1101/2022.03.17.484705v1.full.pdf)

### 2021

_Engineered Swift Equilibration for Arbitrary Geometries_<br>
Adam Frim, Adrianne Zhong, Stephen Chen, Dibyendu Mandal, Michael R DeWeese<br>
[[PRE]](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.103.L030102) [[arXiv]](https://arxiv.org/abs/2012.08672)

_Critical Point-Finding Methods Reveal Gradient-Flat Regions of Deep Network Losses_<br>
Charles Frye, Jamie Simon, Neha Wadia, Andrew Ligeralde, Michael DeWeese, Kris Bouchard<br>
[[Neural Computation]](https://direct.mit.edu/neco/article/33/6/1469/100574/Critical-Point-Finding-Methods-Reveal-Gradient)

### 2020

_Efficient sensory coding of multidimensional stimuli_<br>
Thomas Yerxa, Eric Kee, Michael DeWeese, Emily Cooper<br>
[[PLOS Computational Biology]](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008146)

_Heterogeneous Synaptic Weighting Improves Neural Coding in the Presence of Common Noise_<br>
Pratik Sachdeva, Jesse Livezy, Michael DeWeese<br>
[[Neural Computation]](https://www.mitpressjournals.org/doi/10.1162/neco_a_01287?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%20%200pubmed)

### 2019

_Spike-timing-dependent ensemble encoding by non-classically responsive cortical neurons_<br>
Michele Insanally, Ioana Carcea, Rachel Field, Chris Rodgers, Brian DePasquale, Kanaka Rajan, Michael DeWeese, Badr Albanna, Robert Froemke<br>
[[eLife]](https://elifesciences.org/articles/42409)

_On the sparse structure of natural sounds and natural images: similarities, differences, and implications for neural coding_<br>
Eric Dodds, Michael DeWeese<br>
[[Frontiers in Computational Neuroscience]](https://www.frontiersin.org/articles/10.3389/fncom.2019.00039/full)

_Replay as wavefronts and theta sequences as bump oscillations in a grid cell attractor network_<br>
Louis Kang, Michael DeWeese<br>
[[eLife]](https://elifesciences.org/articles/46351)

_Design of optical neural networks with component imprecisions_<br>
 Michael Fang, Sasikanth Manipatruni, Casimir Wierzynski, Amir Khosrowshahi, Michael DeWeese<br>
[[Optics Express]](https://www.osapublishing.org/oe/fulltext.cfm?uri=oe-27-10-14009&id=411885)

_Numerically recovering the critical points of a deep linear autoencoder_<br>
Charles Frye, Neha Wadia, Michael DeWeese, Kris Bouchard<br>
[[arXiv]](https://arxiv.org/abs/1901.10603)

_Spatial whitening in the retina may be necessary for V1 to learn a sparse representation of natural scenes_<br>
Eric Dodds, Jesse Livezey, Michael DeWeese<br>
[[bioRxiv]](https://www.biorxiv.org/content/10.1101/776799v1.abstract)
