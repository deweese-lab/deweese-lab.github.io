<h3>
	Recent Work
</h3>

<div class="row">
  <div class="col-md-6"><img class='img-responsive center-block' src="/images/other/nn_loss.png"  width="60%" height="60%" />
  <button type="button" class="collapsible">Neural Network Loss Surfaces</button>
		<div class="collapse-content", id="collapse-content">
		<p>
		Despite the fact that the loss functions of deep neural networks are highly non-convex, gradient-based optimization algorithms converge to approximately the same performance from many random initial points. 
		One thread of work has focused on explaining this phenomenon by characterizing the local curvature near critical points of the loss function, where the gradients are near zero, and demonstrating that neural network losses enjoy a no-bad-local-minima property and an abundance of saddle points. 
		
		</p>
		<p>
		The methods used to find these putative critical points suffer from a bad local minima problem of their own: they often converge to or pass through regions where the gradient norm has a stationary point. 
		We call these gradient-flat regions, since they arise when the gradient is approximately in the kernel of the Hessian, such that the loss is locally approximately linear, or flat, in the direction of the gradient. 
		The presence of these regions necessitates care in both interpreting past results that claimed to find critical points of neural network losses and in designing second-order methods for optimizing neural networks.
		</p>
		</div>
  
  </div>
  <div class="col-md-6">
  <img class='img-responsive center-block' src="/images/other/neural_variability.PNG"  width="80%" height="80%" />
  <button type="button" class="collapsible">Neural Coding and Noise</button>
		<div class="collapse-content", id="collapse-content">
		<p>
		Simultaneous recordings from the cortex have revealed that neural activity is highly variable and that some variability is shared across neurons in a population. Further experimental work has demonstrated that the shared component of a neuronal population's variability is 
		typically comparable to or larger than its private component. Meanwhile, an abundance of theoretical work has assessed the impact that shared variability has on a population code. For example, shared input noise is understood to have a detrimental impact on a neural population's coding fidelity. 
		</p>
		<p>
		However, other contributions to variability, such as common noise, can also play a role in shaping correlated variability. We present a network of linear-nonlinear neurons in which we introduce a common noise input to modelâ€”for instance,
		variability resulting from upstream action potentials that are irrelevant to the task at hand. We show that by applying a heterogeneous set of synaptic weights to the neural inputs carrying the common noise, the network can improve its coding ability...
		</p>
		</div>
  
  </div>
  
  
  </div>
