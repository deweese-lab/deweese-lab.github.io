<h3> About the lab </h3>

<p> We are the lab of <a href="{{site.url}}/people/mike_deweese/index.html">Michael DeWeese</a> at UC Berkeley. Our interests fall into three rough categories: </p>

<div class="about-section">
  <div class="about-title"> Nonequilibrium statistical physics.</div>
  <div class="about-info"> Understanding and designing biomolecules and molecular-scale machines will ultimately require deeply understanding statistical physics far from equilibrium. To that end, we're working on developing work-energy theorems for active matter systems and optimal control protocols for systems driven out of equilibrium. We often use techniques from control theory and Riemannian geometry.
  </div>
</div>
<div class="about-section">
  <div class="about-title"> Machine learning theory.</div>
  <div class="about-info"> Deep neural networks have enabled technological wonders from machine translation to image generation, but, remarkably, nobody has a principled understanding of how they work and what they can do. To fill this gap, we're working on developing first-principles theoretical understanding of neural networks, often finding use for tools and concepts from statistical physics. We're also interested in kernel methods and sampling algorithms.
  </div>
</div>
<div class="about-section">
  <div class="about-title"> Systems neuroscience.</div>
  <div class="about-info"> Despite the wealth of neural data acquired in recent years, scientific understanding of how the brain works remains rudimentary. To make progress towards this, we develop biologically-plausible algorithms to model sensory processing and other forms of neural computation, often relying on coding principles such as maximizing sparseness or information flow. Our models clarify the computational roles of different neural populations and provide specific, falsifiable experimental predictions about the structure and activity patterns in biological neural networks.
  </div>
</div>